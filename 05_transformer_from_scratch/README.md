# Transformer From Scratch


## Overview
Build encoder/decoder blocks, residuals, layer norm, position-wise FFN, and positional encodings.

## Key Papers
- Vaswani et al., 2017: Attention Is All You Need

## Tutorials
- Annotated implementations and positional encoding write-ups

## Code Starters
- `src/positional_encoding.py`
- `src/transformer_block.py`
- `src/transformer_seq2seq.py`

## Exercises
- [ ] Train toy transformer on copy/sort/addition tasks
- **Deliverables**: learning curves, error modes
- **Success Metrics**: >99% accuracy on algorithmic toys
